
@article{RicciEide:login14,
    author  = "Robert Ricci and Eric Eide and {The CloudLab Team}",
    title   = "Introducing {CloudLab}: Scientific Infrastructure for Advancing Cloud Architectures and Applications",
    journal = "{USENIX} {;login:}",
    year    = 2014,
    month   = dec,
    volume  = 39,
    number  = 6,
    url = "https://www.usenix.org/publications/login/dec14/ricci"
}


@article{Hu2021LoRA,
    author  = "Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Weizhu Chen and Tie-Yan Liu",
    title   = "LoRA: Low-Rank Adaptation of Large Language Models",
    journal = "arXiv preprint arXiv:2106.09685",
    year    = 2021,
    url     = "https://arxiv.org/abs/2106.09685"
}

@article{yi2023fedlora,
  title={Fedlora: Model-heterogeneous personalized federated learning with lora tuning},
  author={Yi, Liping and Yu, Han and Wang, Gang and Liu, Xiaoguang},
  journal={arXiv preprint arXiv:2310.13283},
  year={2023}
}

@article{huh2024training,
  title={Training Neural Networks from Scratch with Parallel Low-Rank Adapters},
  author={Huh, Minyoung and Cheung, Brian and Bernstein, Jeremy and Isola, Phillip and Agrawal, Pulkit},
  journal={arXiv preprint arXiv:2402.16828},
  year={2024}
}

@inproceedings{lialin2023relora,
  title={ReLoRA: High-Rank Training Through Low-Rank Updates},
  author={Lialin, Vladislav and Muckatira, Sherin and Shivagunde, Namrata and Rumshisky, Anna},
  booktitle={Workshop on Advancing Neural Network Training: Computational Efficiency, Scalability, and Resource Optimization (WANT@ NeurIPS 2023)},
  year={2023}
}

@article{zhao2024loraretriever,
  title={LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild},
  author={Zhao, Ziyu and Gan, Leilei and Wang, Guoyin and Zhou, Wangchunshu and Yang, Hongxia and Kuang, Kun and Wu, Fei},
  journal={arXiv preprint arXiv:2402.09997},
  year={2024}
}

@article{liu2024fingpt,
  title={FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications with High-Performance Computing},
  author={Liu, Xiao-Yang and Zhang, Jie and Wang, Guoxuan and Tong, Weiqing and Walid, Anwar},
  journal={arXiv preprint arXiv:2402.13533},
  year={2024}
}


@article{zhu2023melo,
  title={Melo: Low-rank adaptation is better than fine-tuning for medical image diagnosis},
  author={Zhu, Yitao and Shen, Zhenrong and Zhao, Zihao and Wang, Sheng and Wang, Xin and Zhao, Xiangyu and Shen, Dinggang and Wang, Qian},
  journal={arXiv preprint arXiv:2311.08236},
  year={2023}
}

@misc{Rieke2019FederatedLearning,
    author = "Nicola Rieke",
    title = "What Is Federated Learning?",
    howpublished = "NVIDIA Blog",
    year = "2019",
    month = "October",
    day = "13",
    url = "https://blogs.nvidia.com/blog/what-is-federated-learning/"
}

@misc{zhao2024galore,
      title={GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection}, 
      author={Jiawei Zhao and Zhenyu Zhang and Beidi Chen and Zhangyang Wang and Anima Anandkumar and Yuandong Tian},
      year={2024},
      eprint={2403.03507},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{
    huh2023simplicitybias,
    title={The Low-Rank Simplicity Bias in Deep Networks},
    author={Minyoung Huh and Hossein Mobahi and Richard Zhang and Brian Cheung and Pulkit Agrawal and Phillip Isola},
    journal={Transactions on Machine Learning Research},
    issn={2835-8856},
    year={2023},
    url={https://openreview.net/forum?id=bCiNWDmlY2},
}

@ARTICLE{9782552,
  author={Li, Tao and Tan, Lei and Huang, Zhehao and Tao, Qinghua and Liu, Yipeng and Huang, Xiaolin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Low Dimensional Trajectory Hypothesis is True: DNNs Can Be Trained in Tiny Subspaces}, 
  year={2023},
  volume={45},
  number={3},
  pages={3411-3420},
  keywords={Training;Trajectory;Neural networks;Robustness;Dimensionality reduction;Visualization;Optimization methods;Deep neural network;training;low dimensionality;gradient descent;subspace},
  doi={10.1109/TPAMI.2022.3178101}}

@inproceedings{
le2022training,
title={Training invariances and the low-rank phenomenon: beyond linear networks},
author={Thien Le and Stefanie Jegelka},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=XEW8CQgArno}
}

@article{pytorch-ddp,
author = {Li, Shen and Zhao, Yanli and Varma, Rohan and Salpekar, Omkar and Noordhuis, Pieter and Li, Teng and Paszke, Adam and Smith, Jeff and Vaughan, Brian and Damania, Pritam and Chintala, Soumith},
title = {PyTorch distributed: experiences on accelerating data parallel training},
year = {2020},
issue_date = {August 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3415478.3415530},
doi = {10.14778/3415478.3415530},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {3005–3018},
numpages = {14}
}

@inbook{gpipe,
author = {Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Mia Xu and Chen, Dehao and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V. and Wu, Yonghui and Chen, Zhifeng},
title = {GPipe: efficient training of giant neural networks using pipeline parallelism},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {10},
numpages = {10}
}

@inproceedings{pipedream,
author = {Narayanan, Deepak and Harlap, Aaron and Phanishayee, Amar and Seshadri, Vivek and Devanur, Nikhil R. and Ganger, Gregory R. and Gibbons, Phillip B. and Zaharia, Matei},
title = {PipeDream: generalized pipeline parallelism for DNN training},
year = {2019},
isbn = {9781450368735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341301.3359646},
doi = {10.1145/3341301.3359646},
booktitle = {Proceedings of the 27th ACM Symposium on Operating Systems Principles},
pages = {1–15},
numpages = {15},
location = {Huntsville, Ontario, Canada},
series = {SOSP '19}
}
